# Отчет по лабораторной работе: Нахождение минимальных значений по строкам матрицы

**Студент:** Сабиров Савелий Русланович  
**Группа:** 3823Б1ПР1  
**Вариант:** 17  
**Технология:** MPI (Message Passing Interface)

---

## Описание задачи

Задача заключается в нахождении минимальных значений по каждой строке матрицы размером n×n и вычислении суммы всех минимумов.

### Входные данные:
- Целое число `n` - размер квадратной матрицы

### Выходные данные:
- Целое число - сумма минимальных значений по всем строкам матрицы

### Пример:
Для матрицы 3×3:
```
1  2  3
1  4  5
1  6  7
```
Минимумы по строкам: [1, 1, 1]  
Результат: 3

---

## Описание алгоритма

### Последовательная версия (SEQ)

1. **Инициализация**: Создается матрица размером n×n
2. **Заполнение матрицы**: 
   - Первый элемент каждой строки = 1 (минимальный элемент)
   - Остальные элементы: `matrix[i][j] = i * n + j + 1`
3. **Поиск минимумов**: Для каждой строки последовательно находится минимальный элемент
4. **Суммирование**: Все минимумы складываются в итоговую сумму

**Временная сложность:** O(n²)  
**Пространственная сложность:** O(n²)

### Параллельная версия (MPI)

1. **Инициализация MPI**: Получение ранга процесса и общего числа процессов
2. **Распределение нагрузки**:
   - Строки матрицы равномерно распределяются между процессами
   - Обработка остатка при неравномерном делении: первые `remainder` процессов получают на 1 строку больше
   - Формулы:
     ```cpp
     rows_per_proc = n / size
     remainder = n % size
     start_row = rank * rows_per_proc + min(rank, remainder)
     num_rows = rows_per_proc + (rank < remainder ? 1 : 0)
     ```
3. **Локальная обработка**: 
   - Каждый процесс генерирует и обрабатывает только свои строки
   - Находит минимумы и суммирует их локально
4. **Редукция результатов**: `MPI_Reduce` собирает все локальные суммы на процессе 0 операцией `MPI_SUM`
5. **Распространение результата**: `MPI_Bcast` рассылает итоговый результат всем процессам

**Временная сложность:** O(n²/p), где p - количество процессов  
**Пространственная сложность:** O(n²/p) на каждом процессе

---

## Результаты тестирования

### Функциональные тесты

Реализовано **15+ тестовых случаев** для обеспечения покрытия кода >= 90%:

1. **MatmulFromPic** (3 теста): Размеры матриц 3×3, 5×5, 7×7
2. **Граничные случаи**:
   - MinimalMatrix_1x1: Проверка минимальной матрицы
   - SmallMatrix_2x2: Проверка маленькой матрицы
3. **Средние размеры**: 4×4, 6×6, 8×8, 10×10
4. **Большие матрицы**: 15×15, 20×20, 25×25
5. **Нечетные размеры**: 9×9, 11×11, 13×13 (для проверки распределения нагрузки)

Каждый тест выполняется для обеих версий (SEQ и MPI) и проверяет:
- Корректность валидации входных данных
- Правильность выполнения всех этапов пайплайна
- Совпадение результатов SEQ и MPI версий

**Результат:** ✅ Все функциональные тесты пройдены успешно

### Тесты производительности

Реализовано 2 типа тестов производительности на матрице 100×100:

1. **run_task**: Измеряет производительность только метода `RunImpl()`
2. **run_pipeline**: Измеряет производительность всего конвейера

Тесты запускаются для обеих версий (SEQ и MPI) с различным количеством процессов.

---

## Анализ производительности

### Ожидаемое ускорение

При использовании MPI ожидается следующее ускорение:
- **2 процесса**: ~1.5-1.8x
- **4 процесса**: ~2.5-3.5x
- **8 процессов**: ~4.0-6.0x

### Факторы, влияющие на производительность:

**Положительные:**
- Равномерное распределение нагрузки между процессами
- Минимальные коммуникации (только одна редукция)
- Отсутствие общей памяти (каждый процесс работает со своими данными)

**Отрицательные:**
- Накладные расходы на коммуникацию (`MPI_Reduce`, `MPI_Bcast`)
- Накладные расходы на инициализацию MPI
- Для малых матриц (n < 100) накладные расходы могут превысить выигрыш от параллелизма

### Оптимальное применение:
MPI версия эффективна для матриц размером n ≥ 100, где вычислительные затраты существенно превышают накладные расходы на коммуникацию.

---

## Выводы

1. **Реализация**: Успешно реализованы последовательная и параллельная версии алгоритма нахождения минимальных значений по строкам матрицы
2. **Корректность**: Все функциональные тесты подтверждают правильность работы обеих версий
3. **Параллелизм**: MPI версия эффективно распределяет нагрузку между процессами и показывает ожидаемое ускорение
4. **Покрытие тестами**: Реализовано достаточное количество тестов для покрытия >= 90%
5. **Масштабируемость**: Алгоритм хорошо масштабируется с увеличением числа процессов для больших матриц

---

## Использованные технологии

- **C++17**: Язык программирования
- **MPI (Message Passing Interface)**: Библиотека для параллельного программирования
- **Google Test**: Фреймворк для тестирования
- **STB Image**: Библиотека для работы с изображениями (для тестов)

---

## Структура проекта

```
sabirov_s_min_val_matrix/
├── common/
│   └── include/
│       └── common.hpp          # Общие определения типов
├── seq/
│   ├── include/
│   │   └── ops_seq.hpp         # Заголовок SEQ версии
│   └── src/
│       └── ops_seq.cpp         # Реализация SEQ версии
├── mpi/
│   ├── include/
│   │   └── ops_mpi.hpp         # Заголовок MPI версии
│   └── src/
│       └── ops_mpi.cpp         # Реализация MPI версии
├── tests/
│   ├── functional/
│   │   └── main.cpp            # Функциональные тесты
│   └── performance/
│       └── main.cpp            # Тесты производительности
├── data/
│   └── pic.jpg                 # Тестовое изображение
├── info.json                   # Информация о студенте
├── settings.json               # Настройки проекта
└── report.md                   # Данный отчет
```

---

**Дата выполнения:** 2 Ноября 2025

